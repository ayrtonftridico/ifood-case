{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4eabcb2-4533-4bdc-bb8b-8a90938c470f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from typing import List, Optional, Dict\n",
    "\n",
    "BRONZE_TABLES = {\n",
    "    \"yellow\": \"workspace.nyc_taxi.yellow_trips_bronze\",\n",
    "    \"green\":  \"workspace.nyc_taxi.green_trips_bronze\",\n",
    "    \"fhv\":    \"workspace.nyc_taxi.fhv_trips_bronze\",\n",
    "    \"fhvhv\":  \"workspace.nyc_taxi.fhvhv_trips_bronze\",\n",
    "}\n",
    "\n",
    "SILVER_TABLES = {\n",
    "    \"yellow\": \"workspace.nyc_taxi.yellow_trips_silver\",\n",
    "    \"green\":  \"workspace.nyc_taxi.green_trips_silver\",\n",
    "    \"fhv\":    \"workspace.nyc_taxi.fhv_trips_silver\",\n",
    "    \"fhvhv\":  \"workspace.nyc_taxi.fhvhv_trips_silver\",\n",
    "}\n",
    "\n",
    "\n",
    "CFG: Dict[str, Dict] = {\n",
    "    \"yellow\": {\n",
    "        \"anomes_col\": \"anomes\",\n",
    "        \"essential_cols\": [\"anomes\", \"vendorid\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "        \"pickup_col\": \"tpep_pickup_datetime\",\n",
    "        \"dropoff_col\": \"tpep_dropoff_datetime\",\n",
    "        \"passenger_count_col\": \"passenger_count\",\n",
    "    },\n",
    "    \"green\": {\n",
    "        \"anomes_col\": \"anomes\",\n",
    "        \"essential_cols\": [\"anomes\", \"vendorid\", \"lpep_pickup_datetime\", \"lpep_dropoff_datetime\"],\n",
    "        \"pickup_col\": \"lpep_pickup_datetime\",\n",
    "        \"dropoff_col\": \"lpep_dropoff_datetime\",\n",
    "        \"passenger_count_col\": \"passenger_count\",\n",
    "    },\n",
    "    \"fhv\": {\n",
    "        \"anomes_col\": \"anomes\",\n",
    "        \"essential_cols\": [\"anomes\", \"pickup_datetime\", \"dropoff_datetime\"],\n",
    "        \"pickup_col\": \"pickup_datetime\",\n",
    "        \"dropoff_col\": \"dropoff_datetime\",\n",
    "        \"passenger_count_col\": None,  # n√£o existe em FHV\n",
    "    },\n",
    "    \"fhvhv\": {\n",
    "        \"anomes_col\": \"anomes\",\n",
    "        \"essential_cols\": [\"anomes\", \"pickup_datetime\", \"dropoff_datetime\"],\n",
    "        \"pickup_col\": \"pickup_datetime\",\n",
    "        \"dropoff_col\": \"dropoff_datetime\",\n",
    "        \"passenger_count_col\": None,  # n√£o existe em FHVHV\n",
    "    },\n",
    "}\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Fun√ß√µes gen√©ricas (sem valores fixos internos)\n",
    "# ---------------------------------------------\n",
    "def remove_null_essentials(df, essential_cols: List[str]) -> (int, \"DataFrame\"):\n",
    "    \"\"\"Remove linhas com NULL em QUALQUER coluna essencial.\"\"\"\n",
    "    before = df.count()\n",
    "    cond = None\n",
    "    for c in essential_cols:\n",
    "        expr = F.col(c).isNotNull()\n",
    "        cond = expr if cond is None else (cond & expr)\n",
    "    df = df.filter(cond) if cond is not None else df\n",
    "    after = df.count()\n",
    "    return (before - after), df\n",
    "\n",
    "def remove_small_partitions(df, anomes_col: str, min_pct_of_max: float = 0.05) -> (int, \"DataFrame\"):\n",
    "    \"\"\"Remove parti√ß√µes com contagem < (min_pct_of_max * max_count).\"\"\"\n",
    "    before = df.count()\n",
    "    counts = df.groupBy(anomes_col).count()\n",
    "    max_count = counts.agg(F.max(\"count\")).collect()[0][0]\n",
    "    if max_count is None or max_count == 0:\n",
    "        # nada a fazer\n",
    "        return 0, df\n",
    "    threshold = max_count * min_pct_of_max\n",
    "    valid = counts.filter(F.col(\"count\") >= F.lit(threshold)).select(anomes_col)\n",
    "    df = df.join(valid, on=anomes_col, how=\"inner\")\n",
    "    after = df.count()\n",
    "    return (before - after), df\n",
    "\n",
    "def remove_bad_time_order(df, pickup_col: str, dropoff_col: str) -> (int, \"DataFrame\"):\n",
    "    \"\"\"\n",
    "    Remove registros com ordem temporal inv√°lida.\n",
    "    Assumido aqui: **inv√°lido** quando dropoff < pickup.\n",
    "    (Se voc√™ REALMENTE quiser remover pickup < dropoff, inverta o comparador abaixo.)\n",
    "    \"\"\"\n",
    "    before = df.count()\n",
    "    df = df.filter(F.col(dropoff_col) >= F.col(pickup_col))\n",
    "    after = df.count()\n",
    "    return (before - after), df\n",
    "\n",
    "def remove_nonpositive_passengers(df, passenger_count_col: Optional[str]) -> (int, \"DataFrame\"):\n",
    "    \"\"\"Remove linhas com passenger_count <= 0 (aplicado somente se a coluna existir).\"\"\"\n",
    "    if not passenger_count_col or passenger_count_col not in df.columns:\n",
    "        return 0, df\n",
    "    before = df.count()\n",
    "    df = df.filter(F.col(passenger_count_col) > F.lit(0))\n",
    "    after = df.count()\n",
    "    return (before - after), df\n",
    "\n",
    "def write_delta(df, table: str, anomes_col: str) -> None:\n",
    "    \"\"\"Escreve Silver (Delta) particionada por anomes, sobrescrevendo.\"\"\"\n",
    "    spark.sql(f\"DROP TABLE IF EXISTS {table}\")\n",
    "    (df.repartition(anomes_col)\n",
    "       .write\n",
    "       .format(\"delta\")\n",
    "       .mode(\"overwrite\")\n",
    "       .partitionBy(anomes_col)\n",
    "       .saveAsTable(table))\n",
    "\n",
    "def run_silver_simple(\n",
    "    bronze_table: str,\n",
    "    silver_table: str,\n",
    "    anomes_col: str,\n",
    "    essential_cols: List[str],\n",
    "    pickup_col: str,\n",
    "    dropoff_col: str,\n",
    "    passenger_count_col: Optional[str],\n",
    "    small_part_pct: float = 0.05\n",
    ") -> None:\n",
    "    \"\"\"Executa o pipeline simples de limpeza + escrita da Silver e imprime as m√©tricas de remo√ß√£o.\"\"\"\n",
    "    print(f\"\\n===== SILVER: {silver_table} =====\")\n",
    "    df = spark.table(bronze_table)\n",
    "    total_ini = df.count()\n",
    "    print(f\"üì• Bronze lida: {bronze_table} | Linhas iniciais: {total_ini:,}\")\n",
    "\n",
    "    removed_ess, df = remove_null_essentials(df, essential_cols)\n",
    "    print(f\"üßπ Removidas por colunas essenciais nulas: {removed_ess:,}\")\n",
    "\n",
    "    removed_part, df = remove_small_partitions(df, anomes_col, min_pct_of_max=small_part_pct)\n",
    "    print(f\"üß± Removidas por parti√ß√µes < {int(small_part_pct*100)}% do pico: {removed_part:,}\")\n",
    "\n",
    "    removed_time, df = remove_bad_time_order(df, pickup_col, dropoff_col)\n",
    "    print(f\"‚è±Ô∏è Removidas por ordem temporal inv√°lida (dropoff < pickup): {removed_time:,}\")\n",
    "\n",
    "    removed_pass, df = remove_nonpositive_passengers(df, passenger_count_col)\n",
    "    if passenger_count_col and passenger_count_col in df.columns:\n",
    "        print(f\"üßç Removidas por passenger_count ‚â§ 0: {removed_pass:,}\")\n",
    "    else:\n",
    "        print(f\"üßç Coluna de passageiros ausente ‚Äì regra ignorada.\")\n",
    "\n",
    "    total_fim = df.count()\n",
    "    print(f\"‚úÖ Linhas finais ap√≥s limpeza: {total_fim:,} (removidas no total: {(total_ini - total_fim):,})\")\n",
    "\n",
    "    write_delta(df, silver_table, anomes_col)\n",
    "    print(f\"üíæ Silver gravada: {silver_table}\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Execu√ß√£o por categoria (ligue/desligue √† vontade)\n",
    "# ---------------------------------------------\n",
    "\n",
    "# # Yellow\n",
    "# run_silver_simple(\n",
    "#     bronze_table=BRONZE_TABLES[\"yellow\"],\n",
    "#     silver_table=SILVER_TABLES[\"yellow\"],\n",
    "#     anomes_col=CFG[\"yellow\"][\"anomes_col\"],\n",
    "#     essential_cols=CFG[\"yellow\"][\"essential_cols\"],\n",
    "#     pickup_col=CFG[\"yellow\"][\"pickup_col\"],\n",
    "#     dropoff_col=CFG[\"yellow\"][\"dropoff_col\"],\n",
    "#     passenger_count_col=CFG[\"yellow\"][\"passenger_count_col\"],\n",
    "#     small_part_pct=0.05\n",
    "# )\n",
    "\n",
    "# # Green\n",
    "# run_silver_simple(\n",
    "#     bronze_table=BRONZE_TABLES[\"green\"],\n",
    "#     silver_table=SILVER_TABLES[\"green\"],\n",
    "#     anomes_col=CFG[\"green\"][\"anomes_col\"],\n",
    "#     essential_cols=CFG[\"green\"][\"essential_cols\"],\n",
    "#     pickup_col=CFG[\"green\"][\"pickup_col\"],\n",
    "#     dropoff_col=CFG[\"green\"][\"dropoff_col\"],\n",
    "#     passenger_count_col=CFG[\"green\"][\"passenger_count_col\"],\n",
    "#     small_part_pct=0.05\n",
    "# )\n",
    "\n",
    "# FHV\n",
    "run_silver_simple(\n",
    "    bronze_table=BRONZE_TABLES[\"fhv\"],\n",
    "    silver_table=SILVER_TABLES[\"fhv\"],\n",
    "    anomes_col=CFG[\"fhv\"][\"anomes_col\"],\n",
    "    essential_cols=CFG[\"fhv\"][\"essential_cols\"],\n",
    "    pickup_col=CFG[\"fhv\"][\"pickup_col\"],\n",
    "    dropoff_col=CFG[\"fhv\"][\"dropoff_col\"],\n",
    "    passenger_count_col=CFG[\"fhv\"][\"passenger_count_col\"],\n",
    "    small_part_pct=0.05\n",
    ")\n",
    "\n",
    "# FHVHV\n",
    "run_silver_simple(\n",
    "    bronze_table=BRONZE_TABLES[\"fhvhv\"],\n",
    "    silver_table=SILVER_TABLES[\"fhvhv\"],\n",
    "    anomes_col=CFG[\"fhvhv\"][\"anomes_col\"],\n",
    "    essential_cols=CFG[\"fhvhv\"][\"essential_cols\"],\n",
    "    pickup_col=CFG[\"fhvhv\"][\"pickup_col\"],\n",
    "    dropoff_col=CFG[\"fhvhv\"][\"dropoff_col\"],\n",
    "    passenger_count_col=CFG[\"fhvhv\"][\"passenger_count_col\"],\n",
    "    small_part_pct=0.05\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_transformacao_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
