{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "562f6fc2-be3e-4cea-a282-d8c6d58b0c49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "SILVER = {\n",
    "    \"yellow\": \"workspace.nyc_taxi.yellow_trips_silver\",\n",
    "    \"green\":  \"workspace.nyc_taxi.green_trips_silver\",\n",
    "    \"fhv\":    \"workspace.nyc_taxi.fhv_trips_silver\",\n",
    "    \"fhvhv\":  \"workspace.nyc_taxi.fhvhv_trips_silver\",\n",
    "}\n",
    "\n",
    "GOLD = {\n",
    "    \"yellow_2023_jan_may\": \"workspace.nyc_taxi.yellow_taxi_2023_jan_may_gold\",\n",
    "    \"may_unified\":     \"workspace.nyc_taxi.may_2023_gold\",\n",
    "}\n",
    "\n",
    "# ======================================================\n",
    "# GOLD 1 â€” Yellow (apenas 2023-01 a 2023-05, colunas pedidas)\n",
    "# ======================================================\n",
    "df_yellow_silver = spark.table(SILVER[\"yellow\"])\n",
    "\n",
    "gold1 = (\n",
    "    df_yellow_silver\n",
    "    .filter((F.col(\"anomes\") >= \"202301\") & (F.col(\"anomes\") <= \"202305\"))\n",
    "    .select(\n",
    "        \"vendorid\",\n",
    "        \"passenger_count\",\n",
    "        \"total_amount\",\n",
    "        \"tpep_pickup_datetime\",\n",
    "        \"tpep_dropoff_datetime\",\n",
    "        \"anomes\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“¥ Gold 1 (Yellow 2023/01â€“2023/05) â€“ linhas: {gold1.count():,}\")\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {GOLD['yellow_2023_jan_may']}\")\n",
    "(\n",
    "    gold1\n",
    "    .repartition(\"anomes\")\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"anomes\")\n",
    "    .saveAsTable(GOLD[\"yellow_2023_jan_may\"])\n",
    ")\n",
    "print(f\"âœ… Gravado: {GOLD['yellow_2023_jan_may']}\")\n",
    "\n",
    "# ======================================================\n",
    "# GOLD 2 â€” Unificada Maio/2023 (mÃ­nimo necessÃ¡rio)\n",
    "# Schema final:\n",
    "#   pickup_datetime TIMESTAMP\n",
    "#   passenger_count DOUBLE (nullable)\n",
    "#   anomes STRING\n",
    "# ======================================================\n",
    "\n",
    "# YELLOW -> mantÃ©m passenger_count\n",
    "g_yellow = (\n",
    "    spark.table(SILVER[\"yellow\"])\n",
    "    .filter(F.col(\"anomes\") == \"202305\")\n",
    "    .select(\n",
    "        F.col(\"tpep_pickup_datetime\").alias(\"pickup_datetime\"),\n",
    "        F.col(\"passenger_count\").cast(\"double\").alias(\"passenger_count\"),\n",
    "        F.col(\"anomes\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# GREEN -> mantÃ©m passenger_count\n",
    "g_green = (\n",
    "    spark.table(SILVER[\"green\"])\n",
    "    .filter(F.col(\"anomes\") == \"202305\")\n",
    "    .select(\n",
    "        F.col(\"lpep_pickup_datetime\").alias(\"pickup_datetime\"),\n",
    "        F.col(\"passenger_count\").cast(\"double\").alias(\"passenger_count\"),\n",
    "        F.col(\"anomes\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# FHV -> nÃ£o possui passenger_count (NULL)\n",
    "g_fhv = (\n",
    "    spark.table(SILVER[\"fhv\"])\n",
    "    .filter(F.col(\"anomes\") == \"202305\")\n",
    "    .select(\n",
    "        F.col(\"pickup_datetime\").alias(\"pickup_datetime\"),\n",
    "        F.lit(None).cast(\"double\").alias(\"passenger_count\"),\n",
    "        F.col(\"anomes\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# FHVHV -> tambÃ©m sem passenger_count (NULL)\n",
    "g_fhvhv = (\n",
    "    spark.table(SILVER[\"fhvhv\"])\n",
    "    .filter(F.col(\"anomes\") == \"202305\")\n",
    "    .select(\n",
    "        F.col(\"pickup_datetime\").alias(\"pickup_datetime\"),\n",
    "        F.lit(None).cast(\"double\").alias(\"passenger_count\"),\n",
    "        F.col(\"anomes\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# UniÃ£o mÃ­nima necessÃ¡ria\n",
    "gold2 = (\n",
    "    g_yellow\n",
    "    .unionByName(g_green, allowMissingColumns=True)\n",
    "    .unionByName(g_fhv, allowMissingColumns=True)\n",
    "    .unionByName(g_fhvhv, allowMissingColumns=True)\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“¥ Gold 2 (May/2023) â€“ linhas: {gold2.count():,}\")\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {GOLD['may_unified']}\")\n",
    "(\n",
    "    gold2\n",
    "    .repartition(\"anomes\")\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"anomes\")\n",
    "    .saveAsTable(GOLD[\"may_unified\"])\n",
    ")\n",
    "print(f\"âœ… Gravado: {GOLD['may_unified']}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5860577388461928,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03_transformacao_gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
