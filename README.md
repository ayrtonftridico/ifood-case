# üöñ iFood Data Architecture Case ‚Äî NYC Taxis (Yellow, Green, FHV, FHVHV)

Este projeto implementa um pipeline **reprodut√≠vel** para ingest√£o, padroniza√ß√£o, modelagem e an√°lise dos dados p√∫blicos da **NYC TLC** usando **PySpark** e **Delta Lake** no **Databricks Community Edition** (sem acesso √† internet).
O foco do case √© responder √†s perguntas para **Jan‚ÄìMai/2023**, com √™nfase nas colunas exigidas no enunciado: `VendorID`, `passenger_count`, `total_amount`, `tpep_pickup_datetime`, `tpep_dropoff_datetime`.


> - **Yellow**: Foram utilizados todos os arquivos de **2020‚Äì2025** para exemplificar pr√°ticas de camadas bronze-silver (robustez e volume).
> - **Green, FHV & FHVHV:** apenas **maio/2023** (suficiente para a segunda quest√£o).
> - Todas as an√°lises que exigem ‚Äútodas as frotas‚Äù usam **todos os dados dispon√≠veis por frota** acima; onde uma coluna n√£o existe em determinada frota (ex.: `passenger_count` em FHV/HV), a m√©trica √© computada sobre as frotas que fornecem o campo (documentado nas consultas).

---

## üß≠ Sum√°rio
- [Arquitetura de Dados](#arquitetura-de-dados)
- [Cobertura de Dados (por frota)](#cobertura-de-dados-por-frota)
- [Pr√©-requisitos](#pr√©-requisitos)
- [Como obter os dados (offline)](#como-obter-os-dados-offline)
- [Execu√ß√£o no Databricks CE (passo a passo)](#execu√ß√£o-no-databricks-ce-passo-a-passo)
- [Modelagem e Particionamento](#modelagem-e-particionamento)
- [Consultas de Resposta (SQL)](#consultas-de-resposta-sql)
- [Valida√ß√µes de Qualidade de Dados](#valida√ß√µes-de-qualidade-de-dados)
- [Boas pr√°ticas e performance](#boas-pr√°ticas-e-performance)
- [Estrutura do Reposit√≥rio](#estrutura-do-reposit√≥rio)

---

## üèõÔ∏è Arquitetura de Dados

Camadas (Data Lake):
- **RAW**: arquivos originais exatamente como baixados (Parquet). _Somente leitura_.
- **Bronze**: normaliza√ß√£o m√≠nima de tipos/nomes, coluna t√©cnica `anomes` (YYYYMM) derivada de `*_pickup_datetime`, e **coluna `category`** identificando a frota: `yellow|green|fhv|fhvhv`.
- **Silver**: proje√ß√£o para o escopo do case (Jan‚ÄìMai/2023), colunas solicitadas e filtros de qualidade leves.
- **Gold**: 

Tecnologias:
- **PySpark** para ETL/ELT, **Delta Lake** para armazenamento, **SQL** para consumo anal√≠tico.

---

## üìä Cobertura de Dados (por frota)

| Frota   | Per√≠odo carregado | Observa√ß√µes de schema |
|---------|--------------------|-----------------------|
| Yellow  | 2020‚Äì2025 (todos os meses dispon√≠veis) | Campos `tpep_*`, `passenger_count`, `total_amount` presentes. |
| Green   | **somente 2023-05**                     | Similar a Yellow; colunas `lpep_*` em anos antigos s√£o normalizadas. |
| FHV     | **somente 2023-05**                     | Geralmente **n√£o** possui `passenger_count` e `total_amount`. |
| FHVHV   | **somente 2023-05**                     | Geralmente **n√£o** possui `passenger_count` nem `total_amount`. |

> **Nota metodol√≥gica:** quando uma m√©trica depende de uma coluna ausente numa frota (p.ex. `passenger_count`), a agrega√ß√£o considera **apenas as frotas que fornecem o campo** (Yellow/Green). Isso √© explicitado nas consultas SQL.

---

## üß© Pr√©-requisitos

- Conta no **Databricks Community Edition** (cluster sem internet).
- Download **offline** pr√©vio (feito localmente) e upload para **Volumes** do UC.
- Python 3.10+ localmente apenas se for usar o script de download.
- O `requirements.txt` auxilia na execu√ß√£o local (n√£o √© necess√°rio no Databricks).

---

## üì• Como obter os dados (offline)

Como o Databricks CE **n√£o tem internet**, baixe localmente e depois fa√ßa **upload** para um **Volume**. Script exemplo (ajuste anos/meses conforme sua estrat√©gia):

```python
import os, requests
from concurrent.futures import ThreadPoolExecutor, as_completed

BASE = "https://d37ci6vzurychx.cloudfront.net/trip-data/{}_tripdata_{}-{}.parquet"
CATEGORIES = ["yellow", "green", "fhv", "fhvhv"]
YEARS_FULL = [str(y) for y in range(2020, 2026)]  # uso em yellow/green
MONTHS_FULL = [f"{m:02d}" for m in range(1, 13)]
YEARS_MAY = ["2023"]                               # uso em fhv/fhvhv (maio)
MONTHS_MAY = ["05"]

def plan():
    for cat in CATEGORIES:
        if cat in ("yellow", "green"):
            years, months = YEARS_FULL, MONTHS_FULL
        else:
            years, months = YEARS_MAY, MONTHS_MAY
        for y in years:
            for m in months:
                yield cat, y, m

OUT = "nyc_taxi_raw"
os.makedirs(OUT, exist_ok=True)

def fetch(cat, y, m):
    url = BASE.format(cat, y, m)
    path = os.path.join(OUT, f"{cat}_{y}-{m}.parquet")
    if os.path.exists(path):
        return f"skip {path}"
    try:
        r = requests.get(url, timeout=60)
        if r.status_code == 200:
            with open(path, "wb") as f:
                f.write(r.content)
            return f"ok   {url}"
        return f"miss {url} ({r.status_code})"
    except Exception as e:
        return f"err  {url} ({e})"

with ThreadPoolExecutor(max_workers=8) as ex:
    futures = [ex.submit(fetch, *args) for args in plan()]
    for fut in as_completed(futures):
        print(fut.result())
```

**Upload sugerido (Volumes UC):**
```
/Volumes/workspace/nyc_taxi/raw/yellow/2020-2025/*.parquet
/Volumes/workspace/nyc_taxi/raw/green/2020-2025/*.parquet
/Volumes/workspace/nyc_taxi/raw/fhv/2023-05/*.parquet
/Volumes/workspace/nyc_taxi/raw/fhvhv/2023-05/*.parquet
```

---

## ‚ñ∂Ô∏è Execu√ß√£o no Databricks CE (passo a passo)

1. **Crie os Volumes e fa√ßa o upload** conforme a estrutura acima.

2. **Bronze ‚Äî ingest√£o e normaliza√ß√£o m√≠nima**  
   Notebook `01_ingestao_bronze.ipynb` (exemplo de l√≥gica):
   - Leitura por categoria (diret√≥rios diferentes), padroniza√ß√£o de nomes (`lower`), cast para schema alvo **por frota** e cria√ß√£o da coluna `category`.
   - Deriva√ß√£o de `anomes` a partir de `*_pickup_datetime` (ex.: `tpep_pickup_datetime`, `lpep_pickup_datetime`, `pickup_datetime`).
   - Uni√£o com `unionByName(allowMissingColumns=True)` entre frotas.
   - **Filtro de parti√ß√µes esparsas** (ex.: descartar `anomes` com `< 10k` linhas).
   - Persist√™ncia da Delta Table particionada por `anomes`:
     ```
     workspace.nyc_taxi.trips_sor
     ```

3. **Silver ‚Äî proje√ß√£o para o case**  
   Notebook `02_transformacao_silver.ipynb`:
   - Sele√ß√£o das colunas para o case. Para **compatibilizar frotas**, normalizamos nomes de data/hora para:
     - `pickup_datetime` e `dropoff_datetime` (derivadas de `tpep_*`, `lpep_*` ou `*_datetime`).
   - Filtro **2023-01** a **2023-05**.
   - Particionamento por `anomes` e grava√ß√£o:
     ```
     workspace.nyc_taxi.trips_2023_silver
     ```

4. **An√°lises**  
   Notebook `analysis.ipynb` com consultas SQL (abaixo).

---

## üß± Modelagem e Particionamento

- **Chaves t√©cnicas:** `category` (`yellow|green|fhv|fhvhv`) e `anomes` (`YYYYMM`).
- **Datas unificadas na Silver:** `pickup_datetime`, `dropoff_datetime`.
- **Particionamento por `anomes`** (reflete o **evento real** e otimiza _partition pruning_).

---

## üß™ Consultas de Resposta (SQL)

**1) M√©dia de `total_amount` por m√™s (Jan‚ÄìMai/2023, apenas frotas que possuem `total_amount`):**
```sql
SELECT anomes,
       ROUND(AVG(total_amount), 2) AS media_total_amount
FROM workspace.nyc_taxi.trips_2023_silver
WHERE anomes BETWEEN '202301' AND '202305'
  AND total_amount IS NOT NULL            -- frotas sem esse campo n√£o entram
GROUP BY anomes
ORDER BY anomes;
```

**2) M√©dia de `passenger_count` por hora do dia em Maio/2023 (frotas que possuem `passenger_count`: Yellow/Green):**
```sql
SELECT HOUR(pickup_datetime) AS hora_do_dia,
       ROUND(AVG(passenger_count), 2) AS media_passageiros
FROM workspace.nyc_taxi.trips_2023_silver
WHERE anomes = '202305'
  AND passenger_count IS NOT NULL         -- FHV e FHVHV normalmente n√£o possuem esse campo
GROUP BY hora_do_dia
ORDER BY hora_do_dia;
```

> Se desejar, voc√™ pode adicionar um `GROUP BY category` para comparar o comportamento entre frotas quando a coluna existir.

---

## üîç Valida√ß√µes de Qualidade de Dados

- **Presen√ßa de colunas obrigat√≥rias** na Silver.
- **Nulidade e dom√≠nios:**
  - `pickup_datetime`/`dropoff_datetime` n√£o nulos.
  - `passenger_count >= 0` quando existir.
  - `total_amount >= 0` (admitindo eventuais negativos por ajustes, mas monitorando outliers).
  - `dropoff_datetime >= pickup_datetime`.
- **Volumetria por parti√ß√£o** e alerta para `anomes` com baix√≠ssimo volume.

---

## ‚öôÔ∏è Boas pr√°ticas e performance

- **Delta Lake** (ACID, _time travel_, vacuum).
- **Leitura em lote** por diret√≥rio e `unionByName` com `allowMissingColumns` para esquemas diferentes.
- **`repartition("anomes")`** antes de escrever, melhorando o layout f√≠sico das parti√ß√µes.

---

## üóÇÔ∏è Estrutura do Reposit√≥rio

```
ifood-case/
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ 01_ingestao_bronze.ipynb
‚îÇ  ‚îî‚îÄ 02_transformacao_silver.ipynb
‚îú‚îÄ analysis/
‚îÇ  ‚îî‚îÄ analysis.ipynb
‚îú‚îÄ README.md
‚îî‚îÄ requirements.txt
```

---

## üìå Notas finais

- As escolhas de cobertura por frota (**2020‚Äì2025** para Yellow/Green; **maio/2023** para FHV/FHVHV) foram feitas para **equilibrar escala** e **limita√ß√µes** do Databricks CE, mantendo fidelidade ao enunciado da segunda quest√£o.
- Onde uma coluna n√£o existe na fonte, a m√©trica √© calculada sobre as frotas que **de fato fornecem** o campo ‚Äî isso fica expl√≠cito nos `WHERE ... IS NOT NULL` das consultas.
